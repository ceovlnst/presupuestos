#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Agrupa episodios (Excel grande) sin cargar todo en memoria, usando openpyxl en modo streaming.

- Toma automáticamente un .xlsx que esté en la misma carpeta que este script.
- Agrupa por: columna "Episodio"
- Suma: Producción valorada, Coste TOTAL MAT Y MED, Cantidad, Gastos honorarios
- Mantiene 1 valor (primer no-nulo) para columnas de cabecera (Fecha, Cirujano, etc.)
- Concatena valores únicos (como texto separado por '; ') para columnas de detalle

Salida:
    Crea una carpeta 'salida_unificados' junto al script y dentro un
    archivo 'Resumen_<nombre_original>.xlsx'
"""

from __future__ import annotations

import math
from datetime import datetime, date, timedelta
from collections import defaultdict
from typing import Any, Dict, List, Set
from pathlib import Path  # <-- NUEVO

import pandas as pd
from openpyxl import load_workbook


# =========================
# CONFIG
# =========================

SHEET_NAME  = "Sheet1"

NUMERIC_COLS = [
    "Producción valorada",
    "Coste TOTAL MAT Y MED",
    "Cantidad",
    "Gastos honorarios",
]

SINGLE_VALUE_COLS = [
    "Fecha",
    "CUENTA",
    "Nº Cirugias",
    "Código procedimiento principal",
    "Procedimiento principal",
    "Cirujano principal",
    "Especialidad",
    "Tipo de anestesia",
    "Centro",
    "Garante",
    "Clase garante",
    "Tipo de actividad 1",
    "Tipo de facturación",
    "Mes",
    "Nacionalidad",
    "Tipo gasto",
]

DETAIL_LIST_COLS = [
    "Prestación ID",
    "Tipo prestacion",
    "Prestación",
    "Coste material Unitario",
]

GROUP_KEY = "Episodio"


# =========================
# LOCALIZAR ARCHIVOS
# =========================

BASE_DIR = Path(__file__).resolve().parent

def find_input_file() -> Path:
    """
    Busca automáticamente un archivo .xlsx en la misma carpeta que el script.
    - Ignora archivos temporales de Excel (~$...)
    - Intenta evitar ficheros que ya sean 'Resumen_...'
    - Si hay varios, usa el primero y muestra un aviso.
    """
    xlsx_files = [p for p in BASE_DIR.glob("*.xlsx") if not p.name.startswith("~$")]

    # Evitar usar salidas previas como entrada
    candidates = [p for p in xlsx_files if not p.name.lower().startswith("resumen_")]
    if not candidates:
        candidates = xlsx_files

    if not candidates:
        raise FileNotFoundError(
            f"No se ha encontrado ningún .xlsx en la carpeta: {BASE_DIR}"
        )

    if len(candidates) > 1:
        print("Aviso: se han encontrado varios .xlsx. Usando:", candidates[0].name)

    return candidates[0]


def get_output_path(input_path: Path) -> Path:
    """
    Crea (si no existe) la carpeta 'salida_unificados' junto al script
    y devuelve la ruta de salida tipo 'Resumen_<nombre_original>.xlsx'.
    """
    out_dir = BASE_DIR / "salida_unificados"
    out_dir.mkdir(exist_ok=True)
    return out_dir / f"Resumen_{input_path.name}"


# =========================
# HELPERS
# =========================

def to_float(v: Any) -> float:
    """Convierte a float de forma robusta (None/'' -> 0)."""
    if v is None:
        return 0.0
    if isinstance(v, (int, float)) and not (isinstance(v, float) and math.isnan(v)):
        return float(v)
    s = str(v).strip()
    if s == "" or s.lower() == "nan":
        return 0.0
    try:
        # Cambia coma decimal si viniera así
        s = s.replace(".", "").replace(",", ".") if s.count(",") == 1 and s.count(".") >= 1 else s
        return float(s)
    except Exception:
        return 0.0

def excel_serial_to_date(n: Any) -> Any:
    """
    Convierte serial Excel (por ejemplo 45659) a datetime.date.
    Si ya es date/datetime o no es numérico, lo deja tal cual.
    """
    if isinstance(n, datetime):
        return n.date()
    if isinstance(n, date):
        return n
    if isinstance(n, (int, float)) and not (isinstance(n, float) and math.isnan(n)):
        # Excel usa 1899-12-30 como day 0 en Windows (con bug 1900)
        base = date(1899, 12, 30)
        try:
            return base + timedelta(days=int(n))
        except Exception:
            return n
    return n

def clean_text(v: Any) -> str:
    if v is None:
        return ""
    s = str(v).strip()
    return "" if s.lower() == "nan" else s


# =========================
# STREAMING AGGREGATION
# =========================

def main() -> None:
    # 1) Localizar entrada y salida
    input_path = find_input_file()
    output_path = get_output_path(input_path)

    print("Archivo de entrada:", input_path.name)
    print("Archivo de salida se guardará en:", output_path)

    wb = load_workbook(input_path, read_only=True, data_only=True)
    if SHEET_NAME not in wb.sheetnames:
        raise ValueError(f"No existe la hoja '{SHEET_NAME}'. Hojas: {wb.sheetnames}")

    ws = wb[SHEET_NAME]

    # 2) leer cabecera
    header = None
    for row in ws.iter_rows(min_row=1, max_row=1, values_only=True):
        header = [clean_text(x) for x in row]
    if not header:
        raise ValueError("No se pudo leer la cabecera (fila 1).")

    col_index = {name: idx for idx, name in enumerate(header) if name}
    if GROUP_KEY not in col_index:
        raise ValueError(f"No existe la columna '{GROUP_KEY}' en la cabecera.")

    # Columnas efectivamente presentes
    numeric_cols = [c for c in NUMERIC_COLS if c in col_index]
    single_cols  = [c for c in SINGLE_VALUE_COLS if c in col_index]
    detail_cols  = [c for c in DETAIL_LIST_COLS if c in col_index]

    # Estructuras de agregación
    sums: Dict[Any, Dict[str, float]] = defaultdict(lambda: {c: 0.0 for c in numeric_cols})
    firsts: Dict[Any, Dict[str, Any]] = defaultdict(dict)
    details: Dict[Any, Dict[str, Set[str]]] = defaultdict(lambda: {c: set() for c in detail_cols})
    counts: Dict[Any, int] = defaultdict(int)

    # 3) iterar filas (streaming)
    for r in ws.iter_rows(min_row=2, values_only=True):
        episodio = r[col_index[GROUP_KEY]]
        if episodio is None or str(episodio).strip() == "":
            continue

        counts[episodio] += 1

        # sums
        for c in numeric_cols:
            sums[episodio][c] += to_float(r[col_index[c]])

        # first non-null for header-like columns
        for c in single_cols:
            if c in firsts[episodio]:
                continue
            v = r[col_index[c]]
            if v is None or (isinstance(v, str) and v.strip() == ""):
                continue
            if c == "Fecha":
                v = excel_serial_to_date(v)
            firsts[episodio][c] = v

        # details unique text
        for c in detail_cols:
            v = r[col_index[c]]
            s = clean_text(v)
            if s:
                details[episodio][c].add(s)

    # 4) construir DataFrame de salida
    rows: List[Dict[str, Any]] = []
    for episodio in counts.keys():
        out: Dict[str, Any] = {GROUP_KEY: episodio}

        # single-value cols
        for c in single_cols:
            out[c] = firsts.get(episodio, {}).get(c, None)

        # numeric sums
        for c in numeric_cols:
            out[c] = sums.get(episodio, {}).get(c, 0.0)

        # detail concat
        for c in detail_cols:
            vals = sorted(details.get(episodio, {}).get(c, set()))
            out[c] = "; ".join(vals)

        out["Num_lineas"] = counts[episodio]
        rows.append(out)

    df_out = pd.DataFrame(rows)

    # 5) ordenar columnas: Episodio primero, Num_lineas al final
    desired = [GROUP_KEY] + single_cols + numeric_cols + detail_cols + ["Num_lineas"]
    df_out = df_out[[c for c in desired if c in df_out.columns]]

    # 6) guardar
    df_out.to_excel(output_path, index=False)
    print("Archivo generado:", output_path)
    print("Episodios:", len(df_out), "| Filas originales:", sum(counts.values()))


if __name__ == "__main__":
    main()
